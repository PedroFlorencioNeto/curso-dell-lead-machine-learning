{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Lead Dell Fortaleza - Curso de Machine Learning \n",
    "### Oficina 4 - Processamento da Linguagem Natural com NLTK (<i>Natural Language Toolkit</i>) üì¢Ô∏è\n",
    "\n",
    "Neste notebook iremos aplicar os conhecimentos aprendidos durante a aula de NLP do curso da Lead Dell Fortaleza, usando o texto <b>'Um carro azul seguia rapidamente em uma rodovia, e ao passar por um buraco, o carro furou o pneu, e o motorista desceu do carro azul'</b>\n",
    "\n",
    "Por: Pedro Florencio de Almeida Neto\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceitos importantes:\n",
    "* Corpus: √â um dataset de textos. Na biblioteca NLTK h√° diversos corpus que podemos acessar.\n",
    "\n",
    "* Tokeniza√ß√£o: √â a etapa de pr√©-processamento que capta os termos de um texto e os coloca em uma lista.\n",
    "\n",
    "* Stopwords: S√£o as palavras de um determinado idioma que t√™m pouca relev√¢ncia sem√¢ntica. Por exemplo: 'o','a','dos','das', etc.\n",
    "\n",
    "* Term Frequency-Inverse Document Frequency (TF-IDF): √â uma medida estat√≠stica que permite avaliar a import√¢ncia de uma palavra em um texto. Ela √© composta pela multiplica√ß√£o de dois termos: <i>Term Frequency</i> (frequ√™ncia do termo) que capta a frequ√™ncia que um termo aparece no texto e <i> Inverse Document Frequency</i>  que mede o qu√£o importante ele √©, em um conjunto de todos os documentos. Sua f√≥rmula √© dada por:\n",
    "\n",
    "\n",
    "$$\n",
    "tfidf = \\frac{FrequenciaDoTermo}{NumerodePalavrasDoDocumento} * \\log(\\frac{TotalDeDocumentos}{NumeroDeDocumentosComOTermo})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Instalando as bibliotecas e pacotes necess√°rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/pedroflorencio/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /home/pedroflorencio/anaconda3/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in /home/pedroflorencio/anaconda3/lib/python3.8/site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: click in /home/pedroflorencio/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/pedroflorencio/anaconda3/lib/python3.8/site-packages (from nltk) (4.50.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pedroflorencio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/pedroflorencio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Gerando as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Um carro azul seguia rapidamente em uma rodovia, e ao passar por um buraco, o carro furou o pneu, e o motorista desceu do carro azul'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando os tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Um',\n",
       " 'carro',\n",
       " 'azul',\n",
       " 'seguia',\n",
       " 'rapidamente',\n",
       " 'em',\n",
       " 'uma',\n",
       " 'rodovia',\n",
       " ',',\n",
       " 'e',\n",
       " 'ao',\n",
       " 'passar',\n",
       " 'por',\n",
       " 'um',\n",
       " 'buraco',\n",
       " ',',\n",
       " 'o',\n",
       " 'carro',\n",
       " 'furou',\n",
       " 'o',\n",
       " 'pneu',\n",
       " ',',\n",
       " 'e',\n",
       " 'o',\n",
       " 'motorista',\n",
       " 'desceu',\n",
       " 'do',\n",
       " 'carro',\n",
       " 'azul']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(texto)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificando os tokens sem as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Um\n",
      "carro\n",
      "azul\n",
      "seguia\n",
      "rapidamente\n",
      "rodovia\n",
      "passar\n",
      "buraco\n",
      "carro\n",
      "furou\n",
      "pneu\n",
      "motorista\n",
      "desceu\n",
      "carro\n",
      "azul\n"
     ]
    }
   ],
   "source": [
    "# Removendo as v√≠rgulas, que est√£o presentes na vari√°vel stopwords\n",
    "stopwords.append(\",\")\n",
    "\n",
    "for t in tokens:\n",
    "    if t not in stopwords:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "C√°lculo do TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando fit_transform para para mostrar os tf_idf de cada token do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t0.1796053020267749\n",
      "  (0, 4)\t0.1796053020267749\n",
      "  (0, 8)\t0.1796053020267749\n",
      "  (0, 10)\t0.1796053020267749\n",
      "  (0, 7)\t0.1796053020267749\n",
      "  (0, 2)\t0.1796053020267749\n",
      "  (0, 11)\t0.1796053020267749\n",
      "  (0, 9)\t0.1796053020267749\n",
      "  (0, 0)\t0.1796053020267749\n",
      "  (0, 13)\t0.1796053020267749\n",
      "  (0, 16)\t0.1796053020267749\n",
      "  (0, 6)\t0.1796053020267749\n",
      "  (0, 12)\t0.1796053020267749\n",
      "  (0, 14)\t0.1796053020267749\n",
      "  (0, 1)\t0.3592106040535498\n",
      "  (0, 3)\t0.5388159060803247\n",
      "  (0, 15)\t0.3592106040535498\n"
     ]
    }
   ],
   "source": [
    "vetor = tf_idf.fit_transform([texto])\n",
    "print(vetor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.1796053 , 0.3592106 , 0.1796053 , 0.53881591, 0.1796053 ,\n",
       "         0.1796053 , 0.1796053 , 0.1796053 , 0.1796053 , 0.1796053 ,\n",
       "         0.1796053 , 0.1796053 , 0.1796053 , 0.1796053 , 0.1796053 ,\n",
       "         0.3592106 , 0.1796053 ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando em um vetor\n",
    "vetor = vetor.todense()\n",
    "vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ao',\n",
       " 'azul',\n",
       " 'buraco',\n",
       " 'carro',\n",
       " 'desceu',\n",
       " 'do',\n",
       " 'em',\n",
       " 'furou',\n",
       " 'motorista',\n",
       " 'passar',\n",
       " 'pneu',\n",
       " 'por',\n",
       " 'rapidamente',\n",
       " 'rodovia',\n",
       " 'seguia',\n",
       " 'um',\n",
       " 'uma']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes = tf_idf.get_feature_names()\n",
    "nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ao</th>\n",
       "      <th>azul</th>\n",
       "      <th>buraco</th>\n",
       "      <th>carro</th>\n",
       "      <th>desceu</th>\n",
       "      <th>do</th>\n",
       "      <th>em</th>\n",
       "      <th>furou</th>\n",
       "      <th>motorista</th>\n",
       "      <th>passar</th>\n",
       "      <th>pneu</th>\n",
       "      <th>por</th>\n",
       "      <th>rapidamente</th>\n",
       "      <th>rodovia</th>\n",
       "      <th>seguia</th>\n",
       "      <th>um</th>\n",
       "      <th>uma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.359211</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.538816</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.359211</td>\n",
       "      <td>0.179605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ao      azul    buraco     carro    desceu        do        em  \\\n",
       "0  0.179605  0.359211  0.179605  0.538816  0.179605  0.179605  0.179605   \n",
       "\n",
       "      furou  motorista    passar      pneu       por  rapidamente   rodovia  \\\n",
       "0  0.179605   0.179605  0.179605  0.179605  0.179605     0.179605  0.179605   \n",
       "\n",
       "     seguia        um       uma  \n",
       "0  0.179605  0.359211  0.179605  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame com os scores de TF-IDF associados aos termos\n",
    "df = pd.DataFrame(vetor,columns=nomes)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que \"carro\" e \"azul\" s√£o os termos que possuem os maiores scores, logo aparecem com mais frequ√™ncia no texto.\n",
    "\n",
    "<b>Obrigado!</b>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
